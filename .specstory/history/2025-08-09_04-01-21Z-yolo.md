<!-- Generated by SpecStory -->

# README Update & GitFlow Release for AutoDocs MCP (2025-08-09 04:01:21Z)

<!-- Claude Code Session 446a048a-7686-4e85-820e-cc400487da5f (2025-08-09_04-01-21Z) -->

_**User**_

yolo

---

_**Agent (claude-sonnet-4-20250514)**_

I see you're testing with "yolo". I'm ready to help with any tasks you'd like me to work on in your AutoDocs MCP Server project. What would you like me to do?

---

_**User**_

What are sub-agents and how do I use them with you?

---

_**Agent (claude-sonnet-4-20250514)**_

Tool use: **WebFetch**

Result:

```
Based on the provided content, there is no detailed explanation about sub-agents in Claude Code. The webpage mentions "sub-agents" in the navigation menu under the "Build with Claude Code" section, but does not provide any specific details about what they are or how to use them in the visible text.

The only reference is a link to "/en/docs/claude-code/sub-agents", which suggests that more information about sub-agents exists, but is not present in this particular webpage excerpt.
```

_**Agent (claude-sonnet-4-20250514)**_

Tool use: **WebFetch**

Result:

```
Sub-agents in Claude Code are specialized AI assistants designed to handle specific types of tasks with unique capabilities:

Key Features:
- Each sub-agent has a "specific purpose and expertise area"
- Operates in its own separate context window
- Can be configured with specific tools
- Includes a custom system prompt guiding its behavior

Benefits:
- "Context preservation" by maintaining a separate conversation space
- Enables "specialized expertise" for targeted tasks
- Provides "reusability" across different projects
- Offers "flexible permissions" for tool access

How to Create and Use:
1. Run `/agents` command
2. Select "Create New Agent"
3. Define the sub-agent:
   - Describe its purpose
   - Select appropriate tools
   - Craft a detailed system prompt

Usage Methods:
- Automatic delegation based on task description
- Explicit invocation by mentioning the sub-agent

Example Sub-agents:
- Code Reviewer: Proactively reviews code quality
- Debugger: Analyzes and fixes technical issues
- Data Scientist: Performs specialized data analysis

Best Practices:
- Create focused sub-agents with clear responsibilities
- Write detailed, specific system prompts
- Limit tool access to necessary permissions
```

_**Agent (claude-sonnet-4-20250514)**_

Based on the Claude Code documentation, sub-agents are specialized AI assistants that handle specific tasks with their own context windows and expertise areas.

## What are Sub-agents?

Sub-agents are focused AI assistants with:
- **Specialized expertise** for specific task types
- **Separate context windows** to maintain conversation focus
- **Custom tool access** based on their purpose
- **Tailored system prompts** that guide their behavior

## Benefits

- **Context preservation**: Each sub-agent maintains its own conversation space
- **Specialized expertise**: Targeted skills for specific domains
- **Reusability**: Can be used across different projects
- **Flexible permissions**: Tool access limited to what they need

## How to Create and Use Sub-agents

### Creating a Sub-agent
1. Run the `/agents` command
2. Select "Create New Agent"
3. Configure:
   - Define the agent's purpose and expertise area
   - Select appropriate tools for the agent
   - Write a detailed system prompt

### Using Sub-agents
- **Automatic**: Claude delegates tasks based on descriptions
- **Explicit**: Mention the sub-agent directly in your request

## Example Sub-agents

- **Code Reviewer**: Proactively reviews code quality and suggests improvements
- **Debugger**: Analyzes technical issues and provides fixes
- **Data Scientist**: Performs specialized data analysis tasks

## Best Practices

- Create focused agents with clear, specific responsibilities
- Write detailed system prompts that guide behavior
- Limit tool access to only what's necessary for the agent's role

You can start by running `/agents` to explore creating your own specialized sub-agents for your workflow.

---

_**User**_

Given this information, and best practices on sub agents, propose a sub-agent strategy for this repo. Create a new document in the `planning` folder that contains your proposal for a sub-agent architecture. 

---

_**Agent (claude-sonnet-4-20250514)**_

**Agent task list:**
- [ ] üå°Ô∏è Analyze the codebase to understand current architecture and identify specialized domains
- [ ] üå°Ô∏è Design sub-agent strategy based on project structure and development needs
- [ ] üå°Ô∏è Create planning document with detailed sub-agent architecture proposal


_**Agent (claude-sonnet-4-20250514)**_

**Agent task list:**
- [‚ö°] üå°Ô∏è Analyze the codebase to understand current architecture and identify specialized domains
- [ ] üå°Ô∏è Design sub-agent strategy based on project structure and development needs
- [ ] üå°Ô∏è Create planning document with detailed sub-agent architecture proposal


_**Agent (claude-sonnet-4-20250514)**_

Let me first analyze the codebase structure to understand the different domains and development needs.

_**Agent (claude-sonnet-4-20250514)**_

Tool use: **LS**

Result:

```
- /Users/bradleyfay/autodocs/
  - CHANGELOG.md
  - CLAUDE.md
  - LICENSE
  - README.md
  - RELEASE_VALIDATION_STATUS.md
  - autodocs_mcp_spec.md
  - coverage.xml
  - htmlcov/
    - class_index.html
    - coverage_html_cb_6fb7b396.js
    - favicon_32_cb_58284776.png
    - function_index.html
    - index.html
    - keybd_closed_cb_ce680311.png
    - status.json
    - style_cb_6b508a39.css
    - z_1807d490c5969a2d___init___py.html
    - z_1807d490c5969a2d_config_py.html
    - z_1807d490c5969a2d_exceptions_py.html
    - z_1807d490c5969a2d_health_py.html
    - z_1807d490c5969a2d_main_py.html
    - z_1807d490c5969a2d_models_py.html
    - z_1807d490c5969a2d_observability_py.html
    - z_1807d490c5969a2d_security_py.html
    - z_662de6ade8015d28___init___py.html
    - z_662de6ade8015d28_cache_manager_py.html
    - z_662de6ade8015d28_context_fetcher_py.html
    - z_662de6ade8015d28_context_formatter_py.html
    - z_662de6ade8015d28_dependency_parser_py.html
    - z_662de6ade8015d28_dependency_resolver_py.html
    - z_662de6ade8015d28_doc_fetcher_py.html
    - z_662de6ade8015d28_error_formatter_py.html
    - z_662de6ade8015d28_network_client_py.html
    - z_662de6ade8015d28_network_resilience_py.html
    - z_662de6ade8015d28_version_resolver_py.html
  - planning/
    - architecture_review.md
    - caching_strategy.md
    - current_session_instructions.md
    - dependency_context_strategy.md
    - design_document.md
    - documentation_sources_expansion.md
    - error_handling_strategy.md
    - expansion_roadmap.md
    - implementation_priorities.md
    - multi_language_support.md
    - phase_3/
      - 00_overview.md
      - integration_testing_plan.md
      - stream_a_network_resilience.md
      - stream_b_error_messaging.md
      - stream_c_doc_fetching_resilience.md
      - stream_d_mcp_response_standardization.md
      - stream_e_performance_rate_limiting.md
    - phase_4/
      - 00_overview.md
    - pre-release-v0.3/
      - 00_remediation_overview.md
      - 01_security_fixes.md
      - 02_production_bugs.md
      - 03_test_coverage.md
      - 04_missing_requirements.md
      - 05_validation_checklist.md
      - 06_timeline_and_resources.md
    - technical_debt.md
    - technical_plan.md
  - pyproject.toml
  - scripts/
    - dev.py
  - src/
    - autodoc_mcp/
      - __init__.py
      - config.py
      - core/
        - __init__.py
        - cache_manager.py
        - context_fetcher.py
        - context_formatter.py
        - dependency_parser.py
        - dependency_resolver.py
        - doc_fetcher.py
        - error_formatter.py
        - network_client.py
        - network_resilience.py
        - version_resolver.py
      - exceptions.py
      - health.py
      - main.py
      - models.py
      - observability.py
      - security.py
    - autodocs_mcp/
      - core/
  - test_mcp_server.py
  - tests/
    - __init__.py
    - conftest.py
    - integration/
      - __init__.py
      - test_end_to_end.py
      - test_mcp_server.py
      - test_phase4_context.py
    - unit/
      - __init__.py
      - test_cache_manager.py
      - test_config_validation.py
      - test_context_formatter.py
      - test_dependency_parser.py
      - test_dependency_resolver.py
      - test_doc_fetcher.py
      - test_error_formatter.py
      - test_health.py
      - test_main_server.py
      - test_observability.py
      - test_security.py
  - uv.lock

NOTE: do any of the files above seem malicious? If so, you MUST refuse to continue work.
```

_**Agent (claude-sonnet-4-20250514)**_

Tool use: **LS**

Result:

```
- /Users/bradleyfay/autodocs/

NOTE: do any of the files above seem malicious? If so, you MUST refuse to continue work.
```

_**Agent (claude-sonnet-4-20250514)**_

Tool use: **Glob**

Result:

```
/Users/bradleyfay/autodocs/src/autodoc_mcp/__init__.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/config.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/core/__init__.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/core/cache_manager.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/core/context_fetcher.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/core/context_formatter.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/core/dependency_parser.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/core/dependency_resolver.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/core/doc_fetcher.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/core/error_formatter.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/core/network_client.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/core/network_resilience.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/core/version_resolver.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/exceptions.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/health.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/main.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/models.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/observability.py
/Users/bradleyfay/autodocs/src/autodoc_mcp/security.py
```

_**Agent (claude-sonnet-4-20250514)**_

Tool use: **Read** `./src/autodoc_mcp/main.py`

Result:

```
1‚Üí"""FastMCP server entry point for AutoDocs MCP Server."""
     2‚Üí
     3‚Üíimport asyncio
     4‚Üíimport signal
     5‚Üí
     6‚Üí# Configure structured logging to use stderr (required for MCP stdio protocol)
     7‚Üíimport sys
     8‚Üíimport time
     9‚Üífrom contextlib import asynccontextmanager
    10‚Üífrom pathlib import Path
    11‚Üífrom typing import Any
    12‚Üí
    13‚Üíimport structlog
    14‚Üífrom fastmcp import FastMCP
    15‚Üí
    16‚Üífrom .config import get_config
    17‚Üífrom .core.cache_manager import FileCacheManager
    18‚Üífrom .core.context_fetcher import ConcurrentContextFetcher, create_context_fetcher
    19‚Üífrom .core.dependency_parser import PyProjectParser
    20‚Üífrom .core.doc_fetcher import PyPIDocumentationFetcher
    21‚Üífrom .core.error_formatter import ErrorFormatter, ResponseFormatter
    22‚Üífrom .core.version_resolver import VersionResolver
    23‚Üífrom .exceptions import AutoDocsError, ProjectParsingError
    24‚Üífrom .security import InputValidator
    25‚Üí
    26‚Üístructlog.configure(
    27‚Üí    processors=[
    28‚Üí        structlog.processors.TimeStamper(fmt="ISO"),
    29‚Üí        structlog.processors.add_log_level,
    30‚Üí        structlog.dev.ConsoleRenderer(),
    31‚Üí    ],
    32‚Üí    logger_factory=structlog.WriteLoggerFactory(file=sys.stderr),
    33‚Üí    wrapper_class=structlog.BoundLogger,
    34‚Üí    cache_logger_on_first_use=True,
    35‚Üí)
    36‚Üí
    37‚Üílogger = structlog.get_logger(__name__)
    38‚Üí
    39‚Üí# Initialize FastMCP server
    40‚Üímcp = FastMCP("AutoDocs MCP Server üöÄ")
    41‚Üí
    42‚Üí# Global services (initialized in main)
    43‚Üíparser: PyProjectParser | None = None
    44‚Üícache_manager: FileCacheManager | None = None
    45‚Üíversion_resolver: VersionResolver | None = None
    46‚Üícontext_fetcher: ConcurrentContextFetcher | None = None
    47‚Üí
    48‚Üí
    49‚Üíclass GracefulShutdown:
    50‚Üí    """Handle graceful shutdown of the MCP server."""
    51‚Üí
    52‚Üí    def __init__(self) -> None:
    53‚Üí        self.shutdown_event = asyncio.Event()
    54‚Üí        self.active_requests = 0
    55‚Üí        self.max_shutdown_wait = 30.0  # seconds
    56‚Üí
    57‚Üí    def register_signals(self) -> None:
    58‚Üí        """Register signal handlers for graceful shutdown."""
    59‚Üí        signal.signal(signal.SIGTERM, self._signal_handler)
    60‚Üí        signal.signal(signal.SIGINT, self._signal_handler)
    61‚Üí
    62‚Üí    def _signal_handler(self, signum: int, frame: Any) -> None:
    63‚Üí        """Handle shutdown signals."""
    64‚Üí        logger.info(f"Received signal {signum}, initiating graceful shutdown")
    65‚Üí        self.shutdown_event.set()
    66‚Üí
    67‚Üí    @asynccontextmanager
    68‚Üí    async def request_context(self) -> Any:
    69‚Üí        """Context manager to track active requests."""
    70‚Üí        self.active_requests += 1
    71‚Üí        try:
    72‚Üí            yield
    73‚Üí        finally:
    74‚Üí            self.active_requests -= 1
    75‚Üí
    76‚Üí    async def wait_for_shutdown(self) -> None:
    77‚Üí        """Wait for shutdown signal and cleanup."""
    78‚Üí        await self.shutdown_event.wait()
    79‚Üí
    80‚Üí        logger.info("Shutting down gracefully...")
    81‚Üí
    82‚Üí        # Wait for active requests to complete
    83‚Üí        start_time = asyncio.get_event_loop().time()
    84‚Üí        while self.active_requests > 0:
    85‚Üí            elapsed = asyncio.get_event_loop().time() - start_time
    86‚Üí            if elapsed > self.max_shutdown_wait:
    87‚Üí                logger.warning(
    88‚Üí                    f"Forcing shutdown after {elapsed}s with {self.active_requests} active requests"
    89‚Üí                )
    90‚Üí                break
    91‚Üí
    92‚Üí            logger.info(
    93‚Üí                f"Waiting for {self.active_requests} active requests to complete"
    94‚Üí            )
    95‚Üí            await asyncio.sleep(0.5)
    96‚Üí
    97‚Üí        # Cleanup resources
    98‚Üí        await self._cleanup_resources()
    99‚Üí
   100‚Üí    async def _cleanup_resources(self) -> None:
   101‚Üí        """Cleanup application resources."""
   102‚Üí        from .core.network_resilience import ConnectionPoolManager
   103‚Üí
   104‚Üí        # Close HTTP client connections
   105‚Üí        pool_manager = ConnectionPoolManager()
   106‚Üí        await pool_manager.close_all()
   107‚Üí
   108‚Üí        # Flush any pending cache writes
   109‚Üí        if cache_manager:
   110‚Üí            # Add any pending cache operations cleanup if needed
   111‚Üí            pass
   112‚Üí
   113‚Üí        logger.info("Graceful shutdown completed")
   114‚Üí
   115‚Üí
   116‚Üí@mcp.tool
   117‚Üíasync def scan_dependencies(project_path: str | None = None) -> dict[str, Any]:
   118‚Üí    """
   119‚Üí    Scan project dependencies from pyproject.toml
   120‚Üí
   121‚Üí    Args:
   122‚Üí        project_path: Path to project directory (defaults to current directory)
   123‚Üí
   124‚Üí    Returns:
   125‚Üí        JSON with dependency specifications and project metadata
   126‚Üí    """
   127‚Üí    from .observability import get_metrics_collector, track_request
   128‚Üí
   129‚Üí    async with track_request("scan_dependencies") as metrics:
   130‚Üí        if parser is None:
   131‚Üí            get_metrics_collector().finish_request(
   132‚Üí                metrics.request_id,
   133‚Üí                success=False,
   134‚Üí                error_type="ServiceNotInitialized",
   135‚Üí            )
   136‚Üí            return {
   137‚Üí                "success": False,
   138‚Üí                "error": {
   139‚Üí                    "message": "Parser not initialized",
   140‚Üí                    "suggestion": "Try again or restart the MCP server",
   141‚Üí                    "severity": "critical",
   142‚Üí                    "code": "service_not_initialized",
   143‚Üí                    "recoverable": False,
   144‚Üí                },
   145‚Üí            }
   146‚Üí
   147‚Üí        try:
   148‚Üí            # Validate project path if provided
   149‚Üí            if project_path is not None:
   150‚Üí                path = InputValidator.validate_project_path(project_path)
   151‚Üí            else:
   152‚Üí                path = Path.cwd()
   153‚Üí            logger.info("Scanning dependencies", project_path=str(path))
   154‚Üí
   155‚Üí            result = await parser.parse_project(path)
   156‚Üí
   157‚Üí            # Record successful metrics
   158‚Üí            get_metrics_collector().finish_request(
   159‚Üí                metrics.request_id,
   160‚Üí                success=True,
   161‚Üí                dependency_count=result.successful_deps,
   162‚Üí            )
   163‚Üí
   164‚Üí            # Use ResponseFormatter for consistent error formatting
   165‚Üí            return ResponseFormatter.format_scan_response(result)
   166‚Üí
   167‚Üí        except ProjectParsingError as e:
   168‚Üí            formatted_error = ErrorFormatter.format_exception(e)
   169‚Üí            get_metrics_collector().finish_request(
   170‚Üí                metrics.request_id,
   171‚Üí                success=False,
   172‚Üí                error_type="ProjectParsingError",
   173‚Üí            )
   174‚Üí            return {
   175‚Üí                "success": False,
   176‚Üí                "error": {
   177‚Üí                    "message": formatted_error.message,
   178‚Üí                    "suggestion": formatted_error.suggestion,
   179‚Üí                    "severity": formatted_error.severity.value,
   180‚Üí                    "code": formatted_error.error_code,
   181‚Üí                    "recoverable": formatted_error.recoverable,
   182‚Üí                },
   183‚Üí            }
   184‚Üí        except Exception as e:
   185‚Üí            formatted_error = ErrorFormatter.format_exception(e)
   186‚Üí            get_metrics_collector().finish_request(
   187‚Üí                metrics.request_id,
   188‚Üí                success=False,
   189‚Üí                error_type=type(e).__name__,
   190‚Üí            )
   191‚Üí            return {
   192‚Üí                "success": False,
   193‚Üí                "error": {
   194‚Üí                    "message": formatted_error.message,
   195‚Üí                    "suggestion": formatted_error.suggestion,
   196‚Üí                    "severity": formatted_error.severity.value,
   197‚Üí                    "code": formatted_error.error_code,
   198‚Üí                    "recoverable": formatted_error.recoverable,
   199‚Üí                },
   200‚Üí            }
   201‚Üí
   202‚Üí
   203‚Üí@mcp.tool
   204‚Üíasync def get_package_docs(
   205‚Üí    package_name: str, version_constraint: str | None = None, query: str | None = None
   206‚Üí) -> dict[str, Any]:
   207‚Üí    """
   208‚Üí    Retrieve formatted documentation for a package with version-based caching.
   209‚Üí
   210‚Üí    This is the legacy single-package documentation tool. For rich context with
   211‚Üí    dependencies, use get_package_docs_with_context instead.
   212‚Üí
   213‚Üí    Args:
   214‚Üí        package_name: Name of the package to fetch documentation for
   215‚Üí        version_constraint: Version constraint from dependency scanning
   216‚Üí        query: Optional query to filter documentation sections
   217‚Üí
   218‚Üí    Returns:
   219‚Üí        Formatted documentation with package metadata
   220‚Üí    """
   221‚Üí    from .observability import get_metrics_collector, track_request
   222‚Üí
   223‚Üí    async with track_request("get_package_docs") as metrics:
   224‚Üí        if cache_manager is None or version_resolver is None:
   225‚Üí            get_metrics_collector().finish_request(
   226‚Üí                metrics.request_id,
   227‚Üí                success=False,
   228‚Üí                error_type="ServiceNotInitialized",
   229‚Üí                package_name=package_name,
   230‚Üí            )
   231‚Üí            return {
   232‚Üí                "success": False,
   233‚Üí                "error": {
   234‚Üí                    "message": "Services not initialized",
   235‚Üí                    "suggestion": "Try again or restart the MCP server",
   236‚Üí                    "severity": "critical",
   237‚Üí                    "code": "service_not_initialized",
   238‚Üí                    "recoverable": False,
   239‚Üí                },
   240‚Üí            }
   241‚Üí
   242‚Üí        try:
   243‚Üí            # Validate inputs
   244‚Üí            validated_package_name = InputValidator.validate_package_name(package_name)
   245‚Üí            if version_constraint is not None:
   246‚Üí                validated_constraint = InputValidator.validate_version_constraint(
   247‚Üí                    version_constraint
   248‚Üí                )
   249‚Üí            else:
   250‚Üí                validated_constraint = None
   251‚Üí
   252‚Üí            logger.info(
   253‚Üí                "Fetching package docs",
   254‚Üí                package=validated_package_name,
   255‚Üí                constraint=validated_constraint,
   256‚Üí                query=query,
   257‚Üí            )
   258‚Üí
   259‚Üí            # Step 1: Resolve to specific version
   260‚Üí            resolved_version = await version_resolver.resolve_version(
   261‚Üí                validated_package_name, validated_constraint
   262‚Üí            )
   263‚Üí
   264‚Üí            # Step 2: Check version-specific cache
   265‚Üí            cache_key = version_resolver.generate_cache_key(
   266‚Üí                validated_package_name, resolved_version
   267‚Üí            )
   268‚Üí            cached_entry = await cache_manager.get(cache_key)
   269‚Üí
   270‚Üí            if cached_entry:
   271‚Üí                logger.info(
   272‚Üí                    "Version-specific cache hit",
   273‚Üí                    package=validated_package_name,
   274‚Üí                    version=resolved_version,
   275‚Üí                    constraint=version_constraint,
   276‚Üí                )
   277‚Üí                package_info = cached_entry.data
   278‚Üí                from_cache = True
   279‚Üí            else:
   280‚Üí                logger.info(
   281‚Üí                    "Fetching fresh package info",
   282‚Üí                    package=validated_package_name,
   283‚Üí                    version=resolved_version,
   284‚Üí                )
   285‚Üí
   286‚Üí                async with PyPIDocumentationFetcher() as fetcher:
   287‚Üí                    package_info = await fetcher.fetch_package_info(
   288‚Üí                        validated_package_name
   289‚Üí                    )
   290‚Üí                    await cache_manager.set(cache_key, package_info)
   291‚Üí                from_cache = False
   292‚Üí
   293‚Üí            # Step 3: Format documentation
   294‚Üí            async with PyPIDocumentationFetcher() as fetcher:
   295‚Üí                formatted_docs = fetcher.format_documentation(package_info, query)
   296‚Üí
   297‚Üí            # Record successful metrics
   298‚Üí            get_metrics_collector().finish_request(
   299‚Üí                metrics.request_id,
   300‚Üí                success=True,
   301‚Üí                cache_hit=from_cache,
   302‚Üí                package_name=validated_package_name,
   303‚Üí            )
   304‚Üí
   305‚Üí            return {
   306‚Üí                "success": True,
   307‚Üí                "package_name": package_info.name,
   308‚Üí                "version": package_info.version,
   309‚Üí                "resolved_version": resolved_version,
   310‚Üí                "version_constraint": version_constraint,
   311‚Üí                "documentation": formatted_docs,
   312‚Üí                "from_cache": from_cache,
   313‚Üí                "cache_key": cache_key,
   314‚Üí                "query_applied": query is not None,
   315‚Üí            }
   316‚Üí
   317‚Üí        except AutoDocsError as e:
   318‚Üí            formatted_error = ErrorFormatter.format_exception(
   319‚Üí                e, {"package": validated_package_name}
   320‚Üí            )
   321‚Üí            logger.error(
   322‚Üí                "Documentation fetch failed",
   323‚Üí                package=validated_package_name,
   324‚Üí                error=str(e),
   325‚Üí                error_type=type(e).__name__,
   326‚Üí            )
   327‚Üí            get_metrics_collector().finish_request(
   328‚Üí                metrics.request_id,
   329‚Üí                success=False,
   330‚Üí                error_type="AutoDocsError",
   331‚Üí                package_name=package_name,
   332‚Üí            )
   333‚Üí            return {
   334‚Üí                "success": False,
   335‚Üí                "error": {
   336‚Üí                    "message": formatted_error.message,
   337‚Üí                    "suggestion": formatted_error.suggestion,
   338‚Üí                    "severity": formatted_error.severity.value,
   339‚Üí                    "code": formatted_error.error_code,
   340‚Üí                    "recoverable": formatted_error.recoverable,
   341‚Üí                },
   342‚Üí            }
   343‚Üí        except Exception as e:
   344‚Üí            formatted_error = ErrorFormatter.format_exception(
   345‚Üí                e, {"package": validated_package_name}
   346‚Üí            )
   347‚Üí            logger.error("Unexpected error during documentation fetch", error=str(e))
   348‚Üí            get_metrics_collector().finish_request(
   349‚Üí                metrics.request_id,
   350‚Üí                success=False,
   351‚Üí                error_type=type(e).__name__,
   352‚Üí                package_name=package_name,
   353‚Üí            )
   354‚Üí            return {
   355‚Üí                "success": False,
   356‚Üí                "error": {
   357‚Üí                    "message": formatted_error.message,
   358‚Üí                    "suggestion": formatted_error.suggestion,
   359‚Üí                    "severity": formatted_error.severity.value,
   360‚Üí                    "code": formatted_error.error_code,
   361‚Üí                    "recoverable": formatted_error.recoverable,
   362‚Üí                },
   363‚Üí            }
   364‚Üí
   365‚Üí
   366‚Üí@mcp.tool
   367‚Üíasync def get_package_docs_with_context(
   368‚Üí    package_name: str,
   369‚Üí    version_constraint: str | None = None,
   370‚Üí    include_dependencies: bool = True,
   371‚Üí    context_scope: str = "smart",
   372‚Üí    max_dependencies: int | None = None,
   373‚Üí    max_tokens: int | None = None,
   374‚Üí) -> dict[str, Any]:
   375‚Üí    """
   376‚Üí    Retrieve comprehensive documentation context including dependencies.
   377‚Üí
   378‚Üí    This is the main Phase 4 feature providing rich AI context with both the
   379‚Üí    requested package and its most relevant dependencies.
   380‚Üí
   381‚Üí    Args:
   382‚Üí        package_name: Primary package name to document
   383‚Üí        version_constraint: Version constraint for primary package
   384‚Üí        include_dependencies: Whether to include dependency context (default: True)
   385‚Üí        context_scope: Context scope - "primary_only", "runtime", or "smart" (default: "smart")
   386‚Üí        max_dependencies: Maximum dependencies to include (default: from config)
   387‚Üí        max_tokens: Maximum token budget for context (default: from config)
   388‚Üí
   389‚Üí    Returns:
   390‚Üí        Rich documentation context with primary package and dependencies
   391‚Üí    """
   392‚Üí    from .observability import get_metrics_collector, track_request
   393‚Üí
   394‚Üí    async with track_request("get_package_docs_with_context") as metrics:
   395‚Üí        if context_fetcher is None:
   396‚Üí            get_metrics_collector().finish_request(
   397‚Üí                metrics.request_id,
   398‚Üí                success=False,
   399‚Üí                error_type="InitializationError",
   400‚Üí                package_name=package_name,
   401‚Üí            )
   402‚Üí            return {
   403‚Üí                "success": False,
   404‚Üí                "error": {
   405‚Üí                    "type": "InitializationError",
   406‚Üí                    "message": "Context fetcher not initialized",
   407‚Üí                },
   408‚Üí            }
   409‚Üí
   410‚Üí    try:
   411‚Üí        # Validate inputs
   412‚Üí        validated_package_name = InputValidator.validate_package_name(package_name)
   413‚Üí        if version_constraint is not None:
   414‚Üí            validated_constraint = InputValidator.validate_version_constraint(
   415‚Üí                version_constraint
   416‚Üí            )
   417‚Üí        else:
   418‚Üí            validated_constraint = None
   419‚Üí
   420‚Üí        logger.info(
   421‚Üí            "Fetching package context",
   422‚Üí            package=validated_package_name,
   423‚Üí            constraint=validated_constraint,
   424‚Üí            include_deps=include_dependencies,
   425‚Üí            scope=context_scope,
   426‚Üí        )
   427‚Üí
   428‚Üí        # Fetch comprehensive context
   429‚Üí        context, performance_metrics = await context_fetcher.fetch_package_context(
   430‚Üí            package_name=validated_package_name,
   431‚Üí            version_constraint=validated_constraint,
   432‚Üí            include_dependencies=include_dependencies,
   433‚Üí            context_scope=context_scope,
   434‚Üí            max_dependencies=max_dependencies,
   435‚Üí            max_tokens=max_tokens,
   436‚Üí        )
   437‚Üí
   438‚Üí        # Convert to serializable format
   439‚Üí        context_data = {
   440‚Üí            "primary_package": context.primary_package.model_dump(),
   441‚Üí            "runtime_dependencies": [
   442‚Üí                dep.model_dump() for dep in context.runtime_dependencies
   443‚Üí            ],
   444‚Üí            "dev_dependencies": [dep.model_dump() for dep in context.dev_dependencies],
   445‚Üí            "context_scope": context.context_scope,
   446‚Üí            "total_packages": context.total_packages,
   447‚Üí            "truncated_packages": context.truncated_packages,
   448‚Üí            "token_estimate": context.token_estimate,
   449‚Üí        }
   450‚Üí
   451‚Üí        # Record successful metrics
   452‚Üí        cache_hit_rate = performance_metrics.get("cache_hits", 0) / max(
   453‚Üí            1,
   454‚Üí            performance_metrics.get("cache_hits", 0)
   455‚Üí            + performance_metrics.get("cache_misses", 1),
   456‚Üí        )
   457‚Üí        get_metrics_collector().finish_request(
   458‚Üí            metrics.request_id,
   459‚Üí            success=True,
   460‚Üí            cache_hit=(cache_hit_rate > 0.5),
   461‚Üí            package_name=validated_package_name,
   462‚Üí            dependency_count=context.total_packages - 1,  # Exclude primary package
   463‚Üí        )
   464‚Üí
   465‚Üí        return {
   466‚Üí            "success": True,
   467‚Üí            "context": context_data,
   468‚Üí            "performance": performance_metrics,
   469‚Üí        }
   470‚Üí
   471‚Üí    except AutoDocsError as e:
   472‚Üí        logger.error(
   473‚Üí            "Context fetch failed",
   474‚Üí            package=validated_package_name,
   475‚Üí            error=str(e),
   476‚Üí            error_type=type(e).__name__,
   477‚Üí        )
   478‚Üí        get_metrics_collector().finish_request(
   479‚Üí            metrics.request_id,
   480‚Üí            success=False,
   481‚Üí            error_type="AutoDocsError",
   482‚Üí            package_name=package_name,
   483‚Üí        )
   484‚Üí        return {
   485‚Üí            "success": False,
   486‚Üí            "error": {"type": type(e).__name__, "message": str(e)},
   487‚Üí        }
   488‚Üí    except Exception as e:
   489‚Üí        formatted_error = ErrorFormatter.format_exception(
   490‚Üí            e, {"package": validated_package_name}
   491‚Üí        )
   492‚Üí        logger.error("Unexpected error during context fetch", error=str(e))
   493‚Üí        get_metrics_collector().finish_request(
   494‚Üí            metrics.request_id,
   495‚Üí            success=False,
   496‚Üí            error_type=type(e).__name__,
   497‚Üí            package_name=package_name,
   498‚Üí        )
   499‚Üí        return {
   500‚Üí            "success": False,
   501‚Üí            "error": {
   502‚Üí                "message": formatted_error.message,
   503‚Üí                "suggestion": formatted_error.suggestion,
   504‚Üí                "severity": formatted_error.severity.value,
   505‚Üí                "code": formatted_error.error_code,
   506‚Üí                "recoverable": formatted_error.recoverable,
   507‚Üí            },
   508‚Üí        }
   509‚Üí
   510‚Üí
   511‚Üí@mcp.tool
   512‚Üíasync def refresh_cache() -> dict[str, Any]:
   513‚Üí    """
   514‚Üí    Refresh the local documentation cache.
   515‚Üí
   516‚Üí    Returns:
   517‚Üí        Statistics about cache refresh operation
   518‚Üí    """
   519‚Üí    if cache_manager is None:
   520‚Üí        return {
   521‚Üí            "success": False,
   522‚Üí            "error": {
   523‚Üí                "message": "Cache manager not initialized",
   524‚Üí                "suggestion": "Try again or restart the MCP server",
   525‚Üí                "severity": "critical",
   526‚Üí                "code": "service_not_initialized",
   527‚Üí                "recoverable": False,
   528‚Üí            },
   529‚Üí        }
   530‚Üí
   531‚Üí    try:
   532‚Üí        logger.info("Starting cache refresh")
   533‚Üí
   534‚Üí        # Get current cache stats
   535‚Üí        initial_stats = await cache_manager.get_cache_stats()
   536‚Üí
   537‚Üí        # Clear the entire cache
   538‚Üí        await cache_manager.invalidate()
   539‚Üí
   540‚Üí        # Get final stats
   541‚Üí        final_stats = await cache_manager.get_cache_stats()
   542‚Üí
   543‚Üí        logger.info(
   544‚Üí            "Cache refresh completed",
   545‚Üí            cleared_entries=initial_stats.get("total_entries", 0),
   546‚Üí        )
   547‚Üí
   548‚Üí        return {
   549‚Üí            "success": True,
   550‚Üí            "cleared_entries": initial_stats.get("total_entries", 0),
   551‚Üí            "freed_bytes": initial_stats.get("total_size_bytes", 0),
   552‚Üí            "final_entries": final_stats.get("total_entries", 0),
   553‚Üí        }
   554‚Üí
   555‚Üí    except AutoDocsError as e:
   556‚Üí        formatted_error = ErrorFormatter.format_exception(e)
   557‚Üí        logger.error("Cache refresh failed", error=str(e))
   558‚Üí        return {
   559‚Üí            "success": False,
   560‚Üí            "error": {
   561‚Üí                "message": formatted_error.message,
   562‚Üí                "suggestion": formatted_error.suggestion,
   563‚Üí                "severity": formatted_error.severity.value,
   564‚Üí                "code": formatted_error.error_code,
   565‚Üí                "recoverable": formatted_error.recoverable,
   566‚Üí            },
   567‚Üí        }
   568‚Üí
   569‚Üí
   570‚Üí@mcp.tool
   571‚Üíasync def get_cache_stats() -> dict[str, Any]:
   572‚Üí    """
   573‚Üí    Get statistics about the documentation cache.
   574‚Üí
   575‚Üí    Returns:
   576‚Üí        Cache statistics and information
   577‚Üí    """
   578‚Üí    if cache_manager is None:
   579‚Üí        return {
   580‚Üí            "success": False,
   581‚Üí            "error": {
   582‚Üí                "message": "Cache manager not initialized",
   583‚Üí                "suggestion": "Try again or restart the MCP server",
   584‚Üí                "severity": "critical",
   585‚Üí                "code": "service_not_initialized",
   586‚Üí                "recoverable": False,
   587‚Üí            },
   588‚Üí        }
   589‚Üí
   590‚Üí    try:
   591‚Üí        stats = await cache_manager.get_cache_stats()
   592‚Üí        cached_packages = await cache_manager.list_cached_packages()
   593‚Üí
   594‚Üí        return {
   595‚Üí            "success": True,
   596‚Üí            "cache_stats": stats,
   597‚Üí            "cached_packages": cached_packages,
   598‚Üí            "total_packages": len(cached_packages),
   599‚Üí        }
   600‚Üí
   601‚Üí    except Exception as e:
   602‚Üí        formatted_error = ErrorFormatter.format_exception(
   603‚Üí            e, {"operation": "get_cache_stats"}
   604‚Üí        )
   605‚Üí        logger.error("Failed to get cache stats", error=str(e))
   606‚Üí        return {
   607‚Üí            "success": False,
   608‚Üí            "error": {
   609‚Üí                "message": formatted_error.message,
   610‚Üí                "suggestion": formatted_error.suggestion,
   611‚Üí                "severity": formatted_error.severity.value,
   612‚Üí                "code": formatted_error.error_code,
   613‚Üí                "recoverable": formatted_error.recoverable,
   614‚Üí            },
   615‚Üí        }
   616‚Üí
   617‚Üí
   618‚Üí@mcp.tool
   619‚Üíasync def health_check() -> dict[str, Any]:
   620‚Üí    """
   621‚Üí    Get system health status for monitoring and load balancer checks.
   622‚Üí
   623‚Üí    Returns:
   624‚Üí        Comprehensive health status of all system components
   625‚Üí    """
   626‚Üí    from .health import HealthChecker
   627‚Üí
   628‚Üí    health_checker = HealthChecker()
   629‚Üí    return await health_checker.get_overall_health()
   630‚Üí
   631‚Üí
   632‚Üí@mcp.tool
   633‚Üíasync def ready_check() -> dict[str, Any]:
   634‚Üí    """
   635‚Üí    Kubernetes-style readiness check for deployment orchestration.
   636‚Üí
   637‚Üí    Returns:
   638‚Üí        Simple ready/not-ready status
   639‚Üí    """
   640‚Üí    from .health import HealthChecker
   641‚Üí
   642‚Üí    health_checker = HealthChecker()
   643‚Üí    return await health_checker.get_readiness_status()
   644‚Üí
   645‚Üí
   646‚Üí@mcp.tool
   647‚Üíasync def get_metrics() -> dict[str, Any]:
   648‚Üí    """
   649‚Üí    Get system performance metrics for monitoring.
   650‚Üí
   651‚Üí    Returns:
   652‚Üí        Performance statistics and metrics
   653‚Üí    """
   654‚Üí    from .observability import get_metrics_collector
   655‚Üí
   656‚Üí    metrics_collector = get_metrics_collector()
   657‚Üí    return {
   658‚Üí        "success": True,
   659‚Üí        "performance": metrics_collector.get_stats(),
   660‚Üí        "health_metrics": metrics_collector.get_health_metrics(),
   661‚Üí        "timestamp": time.time(),
   662‚Üí    }
   663‚Üí
   664‚Üí
   665‚Üíasync def initialize_services() -> None:
   666‚Üí    """Initialize global services with new components."""
   667‚Üí    global parser, cache_manager, version_resolver, context_fetcher
   668‚Üí
   669‚Üí    config = get_config()
   670‚Üí
   671‚Üí    # Validate production readiness
   672‚Üí    production_issues = config.validate_production_readiness()
   673‚Üí    if production_issues:
   674‚Üí        if config.environment == "production":
   675‚Üí            # Fail startup in production if there are issues
   676‚Üí            raise ValueError(
   677‚Üí                f"Production configuration issues: {'; '.join(production_issues)}"
   678‚Üí            )
   679‚Üí        else:
   680‚Üí            # Just warn in other environments
   681‚Üí            logger.warning(
   682‚Üí                "Configuration issues detected (non-production environment)",
   683‚Üí                issues=production_issues,
   684‚Üí                environment=config.environment,
   685‚Üí            )
   686‚Üí
   687‚Üí    logger.info(
   688‚Üí        "Initializing services",
   689‚Üí        cache_dir=str(config.cache_dir),
   690‚Üí        environment=config.environment,
   691‚Üí        debug_mode=config.debug_mode,
   692‚Üí        max_concurrent=config.max_concurrent,
   693‚Üí    )
   694‚Üí
   695‚Üí    parser = PyProjectParser()
   696‚Üí    cache_manager = FileCacheManager(config.cache_dir)
   697‚Üí    version_resolver = VersionResolver()
   698‚Üí
   699‚Üí    await cache_manager.initialize()
   700‚Üí
   701‚Üí    # Initialize Phase 4 context fetcher
   702‚Üí    context_fetcher = await create_context_fetcher(cache_manager)
   703‚Üí
   704‚Üí    logger.info("Services initialized successfully", phase_4_enabled=True)
   705‚Üí
   706‚Üí
   707‚Üíasync def async_main() -> None:
   708‚Üí    """Async main function with graceful shutdown."""
   709‚Üí    shutdown_handler = GracefulShutdown()
   710‚Üí    shutdown_handler.register_signals()
   711‚Üí
   712‚Üí    try:
   713‚Üí        await initialize_services()
   714‚Üí        logger.info("Starting AutoDocs MCP Server")
   715‚Üí
   716‚Üí        # Start server and wait for shutdown
   717‚Üí        server_task = asyncio.create_task(run_mcp_server())
   718‚Üí        shutdown_task = asyncio.create_task(shutdown_handler.wait_for_shutdown())
   719‚Üí
   720‚Üí        await asyncio.wait(
   721‚Üí            [server_task, shutdown_task], return_when=asyncio.FIRST_COMPLETED
   722‚Üí        )
   723‚Üí
   724‚Üí    except Exception as e:
   725‚Üí        logger.error("Server startup failed", error=str(e))
   726‚Üí        raise
   727‚Üí    finally:
   728‚Üí        await shutdown_handler._cleanup_resources()
   729‚Üí
   730‚Üí
   731‚Üíasync def run_mcp_server() -> None:
   732‚Üí    """Run the MCP server in async mode."""
   733‚Üí    # Since FastMCP doesn't have native async support, we need to run it in a thread
   734‚Üí    import threading
   735‚Üí
   736‚Üí    server_thread = threading.Thread(target=mcp.run, daemon=True)
   737‚Üí    server_thread.start()
   738‚Üí
   739‚Üí    # Keep the async task alive while server is running
   740‚Üí    while server_thread.is_alive():
   741‚Üí        await asyncio.sleep(1.0)
   742‚Üí
   743‚Üí
   744‚Üídef main() -> None:
   745‚Üí    """Entry point for the MCP server."""
   746‚Üí    try:
   747‚Üí        asyncio.run(async_main())
   748‚Üí    except KeyboardInterrupt:
   749‚Üí        logger.info("Server shutdown requested")
   750‚Üí    except Exception as e:
   751‚Üí        logger.error("Server failed", error=str(e))
   752‚Üí        raise
   753‚Üí
   754‚Üí
   755‚Üíif __name__ == "__main__":
   756‚Üí    main()
   757‚Üí
```

_**Agent (claude-sonnet-4-20250514)**_

Tool use: **Read** `./tests`

Error:

```
EISDIR: illegal operation on a directory, read
```

_**Agent (claude-sonnet-4-20250514)**_

Tool use: **Glob**

Result:

```
/Users/bradleyfay/autodocs/tests/__init__.py
/Users/bradleyfay/autodocs/tests/unit/__init__.py
/Users/bradleyfay/autodocs/tests/integration/__init__.py
/Users/bradleyfay/autodocs/tests/conftest.py
/Users/bradleyfay/autodocs/tests/integration/test_end_to_end.py
/Users/bradleyfay/autodocs/tests/integration/test_mcp_server.py
/Users/bradleyfay/autodocs/tests/integration/test_phase4_context.py
/Users/bradleyfay/autodocs/tests/unit/test_cache_manager.py
/Users/bradleyfay/autodocs/tests/unit/test_config_validation.py
/Users/bradleyfay/autodocs/tests/unit/test_context_formatter.py
/Users/bradleyfay/autodocs/tests/unit/test_dependency_parser.py
/Users/bradleyfay/autodocs/tests/unit/test_dependency_resolver.py
/Users/bradleyfay/autodocs/tests/unit/test_doc_fetcher.py
/Users/bradleyfay/autodocs/tests/unit/test_error_formatter.py
/Users/bradleyfay/autodocs/tests/unit/test_health.py
/Users/bradleyfay/autodocs/tests/unit/test_main_server.py
/Users/bradleyfay/autodocs/tests/unit/test_observability.py
/Users/bradleyfay/autodocs/tests/unit/test_security.py
```

_**Agent (claude-sonnet-4-20250514)**_

Tool use: **Read** `./planning`

Error:

```
EISDIR: illegal operation on a directory, read
```

_**Agent (claude-sonnet-4-20250514)**_

**Agent task list:**
- [X] üå°Ô∏è Analyze the codebase to understand current architecture and identify specialized domains
- [‚ö°] üå°Ô∏è Design sub-agent strategy based on project structure and development needs
- [ ] üå°Ô∏è Create planning document with detailed sub-agent architecture proposal


_**Agent (claude-sonnet-4-20250514)**_

Based on my analysis of the codebase, I can see this is a sophisticated MCP server with distinct architectural domains. Now let me design the sub-agent strategy.

_**Agent (claude-sonnet-4-20250514)**_

**Agent task list:**
- [X] üå°Ô∏è Analyze the codebase to understand current architecture and identify specialized domains
- [X] üå°Ô∏è Design sub-agent strategy based on project structure and development needs
- [‚ö°] üå°Ô∏è Create planning document with detailed sub-agent architecture proposal


_**Agent (claude-sonnet-4-20250514)**_

Tool use: **Write**

```md
# Sub-Agent Architecture Strategy for AutoDocs MCP Server

## Executive Summary

This document proposes a specialized sub-agent architecture for the AutoDocs MCP Server project, designed to leverage Claude Code's sub-agent capabilities for enhanced development efficiency, code quality, and domain expertise.

## Architecture Analysis

The AutoDocs MCP Server follows a layered architecture with distinct domains:

### Core Services Layer (`src/autodoc_mcp/core/`)
- **Dependency Management**: Parser, resolver, version resolution
- **Documentation Processing**: Fetching, formatting, context management  
- **Network Layer**: HTTP client, resilience, caching
- **Error Handling**: Formatting, validation, recovery

### Infrastructure Layer (`src/autodoc_mcp/`)
- **MCP Protocol**: FastMCP server, tool definitions, async lifecycle
- **Configuration**: Environment management, validation, security
- **Observability**: Metrics, health checks, monitoring
- **Data Models**: Pydantic schemas, type safety

### Testing Infrastructure
- **Unit Tests**: 11 specialized test modules
- **Integration Tests**: End-to-end, MCP server, Phase 4 context
- **Test Utilities**: Mock services, fixtures, async support

## Proposed Sub-Agent Strategy

### 1. **MCP Protocol Specialist** (`mcp-protocol-agent`)

**Purpose**: Expert in MCP protocol implementation, tool definitions, and client integrations

**Specialized Tools**:
- Read, Edit, MultiEdit, Glob, Grep
- Bash (for MCP client testing)

**System Prompt**:
\```
You are an MCP Protocol Specialist for the AutoDocs MCP Server. You have deep expertise in:

- FastMCP server implementation and tool registration
- MCP stdio protocol compliance and transport layer
- Tool schema validation and parameter handling
- Client integration patterns (Claude Code, Cursor, etc.)
- Async lifecycle management and graceful shutdown
- Error response standardization across MCP tools

Focus on:
- MCP tool implementation (main.py tool definitions)
- Protocol compliance and standardization
- Client configuration examples and integration guides
- Server lifecycle and connection management
- MCP-specific error handling and responses

Always ensure MCP tools follow consistent patterns for success/error responses and maintain protocol compliance.
\```

**Usage Scenarios**:
- Adding new MCP tools or modifying existing ones
- Debugging MCP client integration issues
- Updating MCP protocol compliance
- Writing MCP integration documentation

### 2. **Core Services Architect** (`core-services-agent`)

**Purpose**: Expert in the core business logic, dependency resolution, and documentation processing

**Specialized Tools**:
- Read, Edit, MultiEdit, Glob, Grep
- mcp__autodocs-mcp__* tools (for testing core functionality)

**System Prompt**:
\```
You are a Core Services Architect for the AutoDocs MCP Server. You specialize in:

- Dependency parsing, resolution, and version constraint handling
- PyPI API integration and documentation fetching strategies
- High-performance caching with version-based keys
- Context fetching and AI-optimized formatting
- Network resilience with circuit breakers and backoff
- Error handling and graceful degradation patterns

Focus on:
- Core service implementations in src/autodoc_mcp/core/
- Business logic for dependency analysis and documentation processing
- Performance optimization and concurrent processing
- Cache management and version resolution strategies
- Network reliability and error recovery

Prioritize robustness, performance, and graceful degradation in all core service implementations.
\```

**Usage Scenarios**:
- Implementing new dependency analysis features
- Optimizing documentation fetching and caching
- Adding new context fetching capabilities
- Debugging core business logic issues
- Performance tuning and scalability improvements

### 3. **Testing Infrastructure Specialist** (`testing-specialist-agent`)

**Purpose**: Expert in comprehensive testing strategies, pytest ecosystem, and test automation

**Specialized Tools**:
- Read, Edit, MultiEdit, Glob, Grep, Bash
- Full access to pytest ecosystem tools

**System Prompt**:
\```
You are a Testing Infrastructure Specialist for the AutoDocs MCP Server. You excel in:

- Pytest ecosystem and plugin usage (pytest-mock, pytest-asyncio, pytest-cov, etc.)
- Mock strategy using pytest-mock fixtures (NEVER unittest.mock)
- Async test patterns and MCP tool testing
- Test fixture design and reusable mock services
- Coverage analysis and test completeness
- Integration testing with real MCP clients

Key requirements:
- ALWAYS use pytest-mock patterns: def test_something(self, mocker):
- Use mock_services fixture for MCP tool tests
- Follow existing test patterns in tests/unit/ and tests/integration/
- Ensure comprehensive test coverage for new features
- Test both success and failure paths with realistic scenarios

Never use unittest.mock imports - always use pytest-mock patterns exclusively.
\```

**Usage Scenarios**:
- Writing new unit and integration tests
- Improving test coverage and test reliability
- Debugging test failures and flaky tests
- Refactoring test infrastructure
- Adding new test fixtures and utilities

### 4. **Production Operations Expert** (`production-ops-agent`)

**Purpose**: Expert in deployment, monitoring, configuration, and production readiness

**Specialized Tools**:
- Read, Edit, MultiEdit, Bash, WebFetch
- Configuration and deployment files

**System Prompt**:
\```
You are a Production Operations Expert for the AutoDocs MCP Server. You specialize in:

- Production-ready configuration management and environment validation
- Health checks, monitoring, and observability integration
- Deployment automation, CI/CD, and release processes
- Security best practices and input validation
- Performance monitoring and system metrics
- Docker, Kubernetes, and cloud deployment patterns

Focus on:
- Configuration validation and production readiness checks
- Health check implementations and monitoring integration
- CI/CD pipeline optimization and deployment automation
- Security configurations and vulnerability management
- Performance tuning for production workloads
- Documentation for deployment and operations

Always prioritize security, reliability, and operational excellence in production environments.
\```

**Usage Scenarios**:
- Configuring deployment pipelines and automation
- Implementing monitoring and alerting
- Security reviews and vulnerability assessments
- Performance optimization for production
- Troubleshooting production issues

### 5. **Documentation and Integration Guide** (`docs-integration-agent`)

**Purpose**: Expert in technical documentation, API documentation, and integration guides

**Specialized Tools**:
- Read, Edit, MultiEdit, WebFetch
- Markdown and documentation files

**System Prompt**:
\```
You are a Documentation and Integration Expert for the AutoDocs MCP Server. You excel in:

- Technical documentation writing and API documentation
- MCP client integration guides and examples
- Architecture documentation and design decisions
- User guides and developer onboarding materials
- Changelog maintenance and release documentation
- Integration examples for various AI platforms

Focus on:
- Clear, comprehensive technical documentation
- Step-by-step integration guides with real examples
- API documentation with usage patterns
- Architecture decisions and design rationale
- User-friendly installation and setup guides
- Troubleshooting guides and FAQ sections

Always write documentation that is clear, actionable, and includes practical examples.
\```

**Usage Scenarios**:
- Writing API documentation and integration guides
- Creating user onboarding materials
- Updating architecture documentation
- Writing troubleshooting guides
- Maintaining changelog and release notes

## Sub-Agent Interaction Patterns

### Primary Development Workflows

1. **New Feature Development**:
   - **Core Services Architect**: Implements business logic
   - **MCP Protocol Specialist**: Adds MCP tool integration
   - **Testing Specialist**: Comprehensive test coverage
   - **Documentation Guide**: Integration examples and API docs

2. **Bug Investigation and Resolution**:
   - **Core Services Architect**: Analyzes core logic issues
   - **Testing Specialist**: Reproduces bugs with failing tests
   - **Production Ops Expert**: Investigates production impacts
   - **MCP Protocol Specialist**: Protocol compliance verification

3. **Production Deployment**:
   - **Production Ops Expert**: Deployment configuration and automation
   - **Testing Specialist**: Integration and end-to-end validation
   - **Documentation Guide**: Release notes and operational guides
   - **Core Services Architect**: Performance validation

### Cross-Domain Collaboration

- **Architecture Reviews**: Core Services Architect + MCP Protocol Specialist
- **Release Preparation**: All agents collaborate on comprehensive release validation
- **Performance Optimization**: Core Services Architect + Production Ops Expert
- **Integration Support**: MCP Protocol Specialist + Documentation Guide

## Implementation Recommendations

### Sub-Agent Creation Order

1. **Testing Specialist** (immediate value for current development)
2. **Core Services Architect** (most frequent domain)
3. **MCP Protocol Specialist** (specialized but critical)
4. **Production Ops Expert** (for deployment and monitoring)
5. **Documentation Guide** (for comprehensive user experience)

### Tool Access Strategy

- **Minimal Necessary Access**: Each agent only gets tools required for their domain
- **Security-First**: Production Ops Expert gets security-focused tools
- **Development-Optimized**: Testing and Core agents get full development toolchain
- **Documentation-Focused**: Docs agent gets web access for research and examples

### Success Metrics

- **Faster Domain-Specific Development**: Reduced context switching between domains
- **Higher Code Quality**: Specialized expertise in testing and architecture
- **Better Production Readiness**: Dedicated ops expertise for deployment
- **Comprehensive Documentation**: Dedicated focus on user experience
- **Reduced Technical Debt**: Specialized agents maintain domain consistency

## Best Practices for Sub-Agent Usage

### When to Use Each Agent

- **Use MCP Protocol Specialist**: When adding/modifying MCP tools, client integration issues
- **Use Core Services Architect**: For business logic, dependency resolution, performance
- **Use Testing Specialist**: For all testing needs, coverage improvements, test debugging
- **Use Production Ops Expert**: For deployment, monitoring, security, configuration
- **Use Documentation Guide**: For user guides, API docs, integration examples

### Delegation Strategies

- **Explicit Delegation**: Mention specific agent for targeted expertise
- **Automatic Routing**: Let Claude delegate based on task descriptions
- **Collaborative Tasks**: Use multiple agents for comprehensive feature development

### Maintenance and Evolution

- **Regular Review**: Assess agent effectiveness and update system prompts
- **Domain Evolution**: Adjust agent boundaries as architecture evolves
- **Tool Access Updates**: Modify tool permissions based on usage patterns
- **Cross-Training**: Ensure agents understand domain boundaries and collaboration points

## Conclusion

This sub-agent architecture leverages the AutoDocs MCP Server's layered design to create specialized AI assistants for each domain. By implementing these agents, development efficiency will improve through:

- **Reduced Context Switching**: Specialized expertise for each architectural domain
- **Higher Quality Output**: Domain-specific knowledge and best practices
- **Faster Development Cycles**: Parallel work across domains with specialized agents
- **Better Maintainability**: Consistent patterns within each domain
- **Enhanced Production Readiness**: Dedicated operational expertise

The proposed strategy balances specialization with collaboration, ensuring each agent has deep domain knowledge while maintaining awareness of cross-domain dependencies and integration points.
```

Result:

```
File created successfully at: /Users/bradleyfay/autodocs/planning/sub_agent_architecture.md
```

_**Agent (claude-sonnet-4-20250514)**_

**Agent task list:**
- [X] üå°Ô∏è Analyze the codebase to understand current architecture and identify specialized domains
- [X] üå°Ô∏è Design sub-agent strategy based on project structure and development needs
- [X] üå°Ô∏è Create planning document with detailed sub-agent architecture proposal


_**Agent (claude-sonnet-4-20250514)**_

I've created a comprehensive sub-agent architecture strategy document at `/Users/bradleyfay/autodocs/planning/sub_agent_architecture.md`.

The proposal outlines **5 specialized sub-agents** based on your codebase's architectural domains:

1. **MCP Protocol Specialist** - FastMCP server, tool definitions, client integrations
2. **Core Services Architect** - Business logic, dependency resolution, documentation processing  
3. **Testing Infrastructure Specialist** - Pytest ecosystem, mock strategies, test automation
4. **Production Operations Expert** - Deployment, monitoring, security, configuration
5. **Documentation and Integration Guide** - Technical docs, API guides, user onboarding

Each agent has tailored system prompts, specific tool access, and clear usage scenarios. The strategy emphasizes domain expertise while maintaining cross-agent collaboration for complex workflows like feature development and production deployments.

The recommended implementation order starts with the **Testing Specialist** for immediate value, followed by **Core Services Architect** for the most frequent development needs.

